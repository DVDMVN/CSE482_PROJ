{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading\n",
    "\n",
    "And some additional preprocessing:\n",
    "- Binning\n",
    "- Tokenization\n",
    "- Resampling (Class Balancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def load_bunch() -> dict[pd.DataFrame]:\n",
    "    apex = pd.read_csv('processed_data/apex_ad2600_dvd_player_updated.csv')\n",
    "    canon = pd.read_csv('processed_data/canon_g3_updated.csv')\n",
    "    nikon = pd.read_csv('processed_data/nikon_coolpix_4300_updated.csv')\n",
    "    nokia = pd.read_csv('processed_data/nokia_6610_updated.csv')\n",
    "    nomad = pd.read_csv('processed_data/nomad_jukebox_zen_xtra_updated.csv')\n",
    "    return {\n",
    "        \"apex\": apex,\n",
    "        \"canon\": canon,\n",
    "        \"nikon\": nikon,\n",
    "        \"nokia\": nokia,\n",
    "        \"nomad\": nomad\n",
    "    }\n",
    "\n",
    "def get_master_df(sentiments_only: bool = True) -> pd.DataFrame:\n",
    "    bunch = load_bunch()\n",
    "    master_df = pd.concat(bunch.values(), ignore_index=True)\n",
    "    master_df['sentiment_dict'] = master_df['sentiment_dict'].apply(ast.literal_eval)\n",
    "    if sentiments_only:\n",
    "        master_df = master_df[master_df['sentiment_dict'].apply(lambda x: bool(x))]\n",
    "    return master_df\n",
    "\n",
    "master_df = get_master_df(sentiments_only = False)\n",
    "\n",
    "# Binning as negative neutral positive\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    master_df['sentiment_total'] > 0,  # Positive sentiment\n",
    "    master_df['sentiment_total'] < 0,  # Negative sentiment\n",
    "    master_df['sentiment_total'] == 0  # Neutral sentiment\n",
    "]\n",
    "\n",
    "# Define corresponding labels\n",
    "labels = ['positive', 'negative', 'neutral']\n",
    "\n",
    "# Create a new column for binned sentiment\n",
    "master_df['sentiment_category'] = np.select(conditions, labels)\n",
    "master_df['sentiment_category'].value_counts()\n",
    "\n",
    "# Tokenization and removal of stopwords\n",
    "master_df['sentence'] = master_df['sentence'].apply(lambda x: remove_stopwords(str(x)))\n",
    "master_df['tokenized_sentence'] = master_df['sentence'].apply(simple_preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_category\n",
      "positive    2000\n",
      "negative    2000\n",
      "neutral     2000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_dict</th>\n",
       "      <th>sentiment_total</th>\n",
       "      <th>[u]</th>\n",
       "      <th>[p]</th>\n",
       "      <th>[s]</th>\n",
       "      <th>[cc]</th>\n",
       "      <th>[cs]</th>\n",
       "      <th>annotations</th>\n",
       "      <th>title_input_ids</th>\n",
       "      <th>title_attention_mask</th>\n",
       "      <th>sentence_input_ids</th>\n",
       "      <th>sentence_attention_mask</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526</td>\n",
       "      <td>a great player excellent sound quality hovewer...</td>\n",
       "      <td>know people software awesome</td>\n",
       "      <td>{'software': 3}</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>software[+3]</td>\n",
       "      <td>[101, 1037, 2307, 2447, 6581, 2614, 3737, 2521...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[101, 1045, 2079, 2025, 2113, 2054, 2060, 2111...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[know, people, software, awesome]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>bad service</td>\n",
       "      <td>send camera nikon service 6 week diagnose problem</td>\n",
       "      <td>{'servicing': -2}</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>servicing[-2]</td>\n",
       "      <td>[101, 2919, 2326, 102, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 1045, 4604, 2026, 4950, 2000, 23205, 223...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[send, camera, nikon, service, week, diagnose,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "      <td>so far it s sweet</td>\n",
       "      <td>s easy pop open song listen</td>\n",
       "      <td>{'case': 2}</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>case[+2][p]</td>\n",
       "      <td>[101, 2061, 2521, 2009, 1055, 4086, 102, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 2009, 1055, 3733, 2438, 2000, 3769, 2009...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[easy, pop, open, song, listen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287</td>\n",
       "      <td>no picture and or no sound try ip button on th...</td>\n",
       "      <td>product month yesterday stop work</td>\n",
       "      <td>{'product': -3}</td>\n",
       "      <td>-3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>product[-3][u]</td>\n",
       "      <td>[101, 2053, 3861, 1998, 2030, 2053, 2614, 3046...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[101, 2057, 2031, 2031, 2023, 4031, 2005, 2058...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[product, month, yesterday, stop, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>good phone so-so service</td>\n",
       "      <td>reason ?</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[101, 2204, 3042, 2061, 1011, 2061, 2326, 102,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 3114, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[reason]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        1526  a great player excellent sound quality hovewer...   \n",
       "1          55                                        bad service   \n",
       "2         269                                  so far it s sweet   \n",
       "3         287  no picture and or no sound try ip button on th...   \n",
       "4          34                           good phone so-so service   \n",
       "\n",
       "                                            sentence     sentiment_dict  \\\n",
       "0                       know people software awesome    {'software': 3}   \n",
       "1  send camera nikon service 6 week diagnose problem  {'servicing': -2}   \n",
       "2                        s easy pop open song listen        {'case': 2}   \n",
       "3                  product month yesterday stop work    {'product': -3}   \n",
       "4                                           reason ?                 {}   \n",
       "\n",
       "   sentiment_total    [u]    [p]    [s]   [cc]   [cs]     annotations  \\\n",
       "0                3  False  False  False  False  False    software[+3]   \n",
       "1               -2  False  False  False  False  False   servicing[-2]   \n",
       "2                2  False   True  False  False  False     case[+2][p]   \n",
       "3               -3   True  False  False  False  False  product[-3][u]   \n",
       "4                0  False  False  False  False  False             NaN   \n",
       "\n",
       "                                     title_input_ids  \\\n",
       "0  [101, 1037, 2307, 2447, 6581, 2614, 3737, 2521...   \n",
       "1  [101, 2919, 2326, 102, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [101, 2061, 2521, 2009, 1055, 4086, 102, 0, 0,...   \n",
       "3  [101, 2053, 3861, 1998, 2030, 2053, 2614, 3046...   \n",
       "4  [101, 2204, 3042, 2061, 1011, 2061, 2326, 102,...   \n",
       "\n",
       "                                title_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  sentence_input_ids  \\\n",
       "0  [101, 1045, 2079, 2025, 2113, 2054, 2060, 2111...   \n",
       "1  [101, 1045, 4604, 2026, 4950, 2000, 23205, 223...   \n",
       "2  [101, 2009, 1055, 3733, 2438, 2000, 3769, 2009...   \n",
       "3  [101, 2057, 2031, 2031, 2023, 4031, 2005, 2058...   \n",
       "4  [101, 3114, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                             sentence_attention_mask sentiment_category  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           positive   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           negative   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           positive   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           negative   \n",
       "4  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            neutral   \n",
       "\n",
       "                                  tokenized_sentence  \n",
       "0                  [know, people, software, awesome]  \n",
       "1  [send, camera, nikon, service, week, diagnose,...  \n",
       "2                    [easy, pop, open, song, listen]  \n",
       "3            [product, month, yesterday, stop, work]  \n",
       "4                                           [reason]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "positive_df = master_df[master_df['sentiment_category'] == 'positive']\n",
    "negative_df = master_df[master_df['sentiment_category'] == 'negative']\n",
    "neutral_df = master_df[master_df['sentiment_category'] == 'neutral']\n",
    "\n",
    "max_size = 2000\n",
    "\n",
    "# Resample each class to match the majority class size\n",
    "positive_upsampled = resample(positive_df, replace=True, n_samples=max_size, random_state=42)\n",
    "negative_upsampled = resample(negative_df, replace=True, n_samples=max_size, random_state=42)\n",
    "neutral_upsampled = resample(neutral_df, replace=True, n_samples=max_size, random_state=42)\n",
    "\n",
    "# Combine the upsampled dataframes\n",
    "balanced_master_df = pd.concat([positive_upsampled, negative_upsampled, neutral_upsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_master_df = balanced_master_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(balanced_master_df['sentiment_category'].value_counts())\n",
    "display(balanced_master_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 0.5068459510803223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "train_df, test_df = train_test_split(balanced_master_df, test_size=0.2, random_state=1111)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the Word2Vec Model\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_df['tokenized_sentence'],\n",
    "    vector_size=150,\n",
    "    workers=3,\n",
    "    window=3,\n",
    "    min_count=1,\n",
    "    sg=1, # Skip Gram\n",
    ")\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sentence vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sentence, model):\n",
    "    valid_words = [word for word in sentence if word in model.wv]\n",
    "    if len(valid_words) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no valid words\n",
    "    return np.mean([model.wv[word] for word in valid_words], axis=0) # Takes the average of all the word vectors to create a sentence vector\n",
    "\n",
    "train_df['sentence_vector'] = train_df['tokenized_sentence'].apply(lambda x: sentence_vector(x, w2v_model))\n",
    "test_df['sentence_vector'] = test_df['tokenized_sentence'].apply(lambda x: sentence_vector(x, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "\n",
      "Decision Tree Accuracy: 0.8908\n",
      "Decision Tree F1-Score: 0.8899\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94       398\n",
      "     neutral       0.88      0.81      0.85       386\n",
      "    positive       0.88      0.89      0.89       416\n",
      "\n",
      "    accuracy                           0.89      1200\n",
      "   macro avg       0.89      0.89      0.89      1200\n",
      "weighted avg       0.89      0.89      0.89      1200\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Accuracy: 0.4783\n",
      "Logistic Regression F1-Score: 0.4802\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.50      0.49       398\n",
      "     neutral       0.41      0.45      0.43       386\n",
      "    positive       0.56      0.48      0.52       416\n",
      "\n",
      "    accuracy                           0.48      1200\n",
      "   macro avg       0.48      0.48      0.48      1200\n",
      "weighted avg       0.49      0.48      0.48      1200\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Accuracy: 0.9017\n",
      "Random Forest F1-Score: 0.9013\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94       398\n",
      "     neutral       0.88      0.85      0.87       386\n",
      "    positive       0.90      0.90      0.90       416\n",
      "\n",
      "    accuracy                           0.90      1200\n",
      "   macro avg       0.90      0.90      0.90      1200\n",
      "weighted avg       0.90      0.90      0.90      1200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "training_vectors = np.vstack(train_df['sentence_vector'])\n",
    "training_categories = train_df['sentiment_category']\n",
    "\n",
    "testing_vectors = np.vstack(test_df['sentence_vector'])\n",
    "testing_categories = test_df['sentiment_category']\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=1111),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=1111),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=1111)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"\\n{model_name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"{model_name} F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\\n\")\n",
    "        print(f\"{model_name} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "train_and_evaluate(models, training_vectors, training_categories, testing_vectors, testing_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "import random\n",
    "\n",
    "train_df, test_df = train_test_split(balanced_master_df, test_size=0.2, random_state=1111)\n",
    "\n",
    "d2v_model = Doc2Vec(\n",
    "    vector_size=100,\n",
    "    workers=3,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "def tag_sentence(tokenized_sentence, tag):\n",
    "    return TaggedDocument(tokenized_sentence, tag)\n",
    "tagged_sentences = []\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "neu_count = 0\n",
    "for _, row in train_df.iterrows():\n",
    "    if row['sentiment_category'] == 'positive':\n",
    "        pos_count += 1\n",
    "        tagged_sentence = tag_sentence(row['tokenized_sentence'], [\"POS_\" + str(pos_count)])\n",
    "    elif row['sentiment_category'] == 'negative':\n",
    "        neg_count += 1\n",
    "        tagged_sentence = tag_sentence(row['tokenized_sentence'], [\"NEG_\" + str(neg_count)])\n",
    "    elif row['sentiment_category'] == 'neutral':\n",
    "        neu_count += 1\n",
    "        tagged_sentence = tag_sentence(row['tokenized_sentence'], [\"NEU_\" + str(neu_count)])\n",
    "    tagged_sentences.append(tagged_sentence)\n",
    "\n",
    "d2v_model.build_vocab(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_perm(sentences):\n",
    "    shuffled = list(sentences)\n",
    "    random.shuffle(shuffled)\n",
    "    return shuffled\n",
    "\n",
    "d2v_model.train(tagged_sentences, total_examples=d2v_model.corpus_count, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584\n",
      "1602\n",
      "1614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('solid', 0.8693687915802002),\n",
       " ('flimsy', 0.8567082285881042),\n",
       " ('plastic', 0.8540900945663452),\n",
       " ('uneasy', 0.8526702523231506),\n",
       " ('cute', 0.8403142094612122),\n",
       " ('comfy', 0.8125000596046448),\n",
       " ('tiny', 0.8041970133781433),\n",
       " ('mechanically', 0.7985464334487915),\n",
       " ('autofocus', 0.7975852489471436),\n",
       " ('awkward', 0.7911451458930969)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pos_count)\n",
    "print(neg_count)\n",
    "print(neu_count)\n",
    "\n",
    "d2v_model.wv.most_similar(\"feel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(pos_count):\n",
    "    prefix_train = 'POS_' + str(i + 1)\n",
    "    train_array.append(d2v_model[prefix_train])\n",
    "    train_labels.append(1)\n",
    "\n",
    "for i in range(neg_count):\n",
    "    prefix_train = 'NEG_' + str(i + 1)\n",
    "    train_array.append(d2v_model[prefix_train])\n",
    "    train_labels.append(-1)\n",
    "\n",
    "for i in range(neu_count):\n",
    "    prefix_train = 'NEU_' + str(i + 1)\n",
    "    train_array.append(d2v_model[prefix_train])\n",
    "    train_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "\n",
      "Decision Tree Accuracy: 0.4100\n",
      "Decision Tree F1-Score: 0.4108\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.43      0.44       398\n",
      "           0       0.36      0.40      0.38       386\n",
      "           1       0.42      0.40      0.41       416\n",
      "\n",
      "    accuracy                           0.41      1200\n",
      "   macro avg       0.41      0.41      0.41      1200\n",
      "weighted avg       0.41      0.41      0.41      1200\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Accuracy: 0.5575\n",
      "Logistic Regression F1-Score: 0.5563\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.60      0.58       398\n",
      "           0       0.52      0.47      0.50       386\n",
      "           1       0.59      0.59      0.59       416\n",
      "\n",
      "    accuracy                           0.56      1200\n",
      "   macro avg       0.56      0.56      0.56      1200\n",
      "weighted avg       0.56      0.56      0.56      1200\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Accuracy: 0.6658\n",
      "Random Forest F1-Score: 0.6667\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.63      0.67       398\n",
      "           0       0.59      0.66      0.62       386\n",
      "           1       0.70      0.71      0.71       416\n",
      "\n",
      "    accuracy                           0.67      1200\n",
      "   macro avg       0.67      0.67      0.67      1200\n",
      "weighted avg       0.67      0.67      0.67      1200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_array = []\n",
    "test_labels = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    test_vector = d2v_model.infer_vector(row['tokenized_sentence'])  # Infer vector for test sentence\n",
    "    test_array.append(test_vector)\n",
    "    if row['sentiment_category'] == 'positive':\n",
    "        test_labels.append(1)\n",
    "    elif row['sentiment_category'] == 'negative':\n",
    "        test_labels.append(-1)\n",
    "    elif row['sentiment_category'] == 'neutral':\n",
    "        test_labels.append(0)\n",
    "\n",
    "\n",
    "# # Calculate class weights\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',  # Balances weights inversely proportional to class frequencies\n",
    "#     classes=np.unique(train_labels),  # Unique class labels\n",
    "#     y=train_labels                # Training labels\n",
    "# )\n",
    "\n",
    "# # Convert to dictionary format for use in classifiers\n",
    "# class_weight_dict = {label: weight for label, weight in zip(np.unique(train_labels), class_weights)}\n",
    "# print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Decision Tree\n",
    "# classifier = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "# models = {\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "#     \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "#     \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# classifier = DecisionTreeClassifier()\n",
    "# classifier.fit(train_array, train_labels)\n",
    "# y_pred = classifier.predict(test_array)\n",
    "# print(\"Decision Tree Accuracy:\", accuracy_score(test_labels, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(test_labels, y_pred))\n",
    "\n",
    "# # Logistic Regression\n",
    "# # classifier = LogisticRegression(class_weight='balanced')\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(train_array, train_labels)\n",
    "# y_pred = classifier.predict(test_array)\n",
    "# print(\"Logistic Regression Accuracy:\", accuracy_score(test_labels, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(test_labels, y_pred))\n",
    "\n",
    "\n",
    "# # Random Forest\n",
    "# # classifier = RandomForestClassifier(class_weight='balanced')\n",
    "# classifier = RandomForestClassifier()\n",
    "# classifier.fit(train_array, train_labels)\n",
    "# y_pred = classifier.predict(test_array)\n",
    "# print(\"Random Forest Accuracy:\", accuracy_score(test_labels, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(test_labels, y_pred))\n",
    "\n",
    "train_and_evaluate(models, train_array, train_labels, test_array, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cherry', 0.9183273911476135)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-twitter-25\")\n",
    "model.most_similar(positive=['fruit', 'flower'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.855000\n",
      "F1:  0.8534687625641862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90       400\n",
      "     neutral       0.87      0.76      0.81       400\n",
      "    positive       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.85      1200\n",
      "   macro avg       0.86      0.85      0.85      1200\n",
      "weighted avg       0.86      0.85      0.85      1200\n",
      "\n",
      "Accuracy: 0.499167\n",
      "F1:  0.4981465550647136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.51      0.50       400\n",
      "     neutral       0.49      0.44      0.46       400\n",
      "    positive       0.52      0.55      0.54       400\n",
      "\n",
      "    accuracy                           0.50      1200\n",
      "   macro avg       0.50      0.50      0.50      1200\n",
      "weighted avg       0.50      0.50      0.50      1200\n",
      "\n",
      "Accuracy: 0.895000\n",
      "F1:  0.8945353476771345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94       400\n",
      "     neutral       0.90      0.82      0.86       400\n",
      "    positive       0.86      0.92      0.88       400\n",
      "\n",
      "    accuracy                           0.90      1200\n",
      "   macro avg       0.90      0.90      0.89      1200\n",
      "weighted avg       0.90      0.90      0.89      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load GloVe model\n",
    "# model = api.load(\"glove-twitter-25\")\n",
    "\n",
    "# Sample data\n",
    "tokenized_sentences = balanced_master_df['tokenized_sentence']  # Your tokenized sentences\n",
    "sentiment_labels = balanced_master_df['sentiment_category']     # Corresponding sentiment labels\n",
    "\n",
    "# Generate sentence embeddings\n",
    "def sentence_embedding(sentence_tokens, model):\n",
    "    embeddings = [model[word] for word in sentence_tokens if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "X = [sentence_embedding(tokens, model) for tokens in tokenized_sentences]\n",
    "y = sentiment_labels\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):4f}\")\n",
    "print(\"F1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train the classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):4f}\")\n",
    "print(\"F1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):4f}\")\n",
    "print(\"F1: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
