{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dataset:\n",
    "\n",
    "Sourced from [cs.uic.edu](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)\n",
    "- Currently analyzing [Customer Review Datasets (5 products)](http://www.cs.uic.edu/~liub/FBS/CustomerReviewData.zip)\n",
    "- Contains reviews for 5 products:\n",
    "\t1. digital camera: Canon G3\n",
    "\t2. digital camera: Nikon coolpix 4300\n",
    "\t3. celluar phone:  Nokia 6610\n",
    "\t4. mp3 player:     Creative Labs Nomad Jukebox Zen Xtra 40GB\n",
    "\t5. dvd player:     Apex AD2600 Progressive-scan DVD player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing raw text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- One sentence within text file does not have a ## to split on, mistakenly only have one pound sign #. Found on line number: 485\n",
    "- Some of the sentences have broken brackets, these won't be picked up by the annotation extraction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "raw_container_path = 'raw_data/customer review data/'\n",
    "\n",
    "file_name_dict = {\n",
    "    'canon_g3': \"Canon G3.txt\",\n",
    "    'nikon_coolpix_4300': \"Nikon coolpix 4300.txt\",\n",
    "    'nokia_6610': \"Nokia 6610.txt\",\n",
    "    'nomad_jukebox_zen_xtra': \"Creative Labs Nomad Jukebox Zen Xtra 40GB.txt\",\n",
    "    'apex_ad2600_dvd_player': \"Apex AD2600 Progressive-scan DVD player.txt\",\n",
    "}\n",
    "\n",
    "# Working on the parsing of the annotations part: Testing out how I can parse this annotations section to extract information\n",
    "def extract_sentiment(annotations_part: str) -> list[dict, int]:\n",
    "    feature_sentiment_dict = {}\n",
    "    sentiment_value_total = 0\n",
    "    feature_sentiment_matches =  re.findall(r'(.*?)\\[(\\+|-)(\\d)\\]', annotations_part) # Just for extracting the \"feature|[+|- sentiment]\"\n",
    "    for match in feature_sentiment_matches:\n",
    "        feature_name = match[0]\n",
    "        if match[1] == '+':\n",
    "            sentiment = int(match[2])\n",
    "        elif match[1] == '-':\n",
    "            sentiment = int(match[2]) * -1\n",
    "        else:\n",
    "            raise Exception(\"Invalid sentiment: \" + match[1])\n",
    "        feature_sentiment_dict[feature_name] = sentiment\n",
    "        sentiment_value_total += sentiment\n",
    "    return feature_sentiment_dict, sentiment_value_total\n",
    "\n",
    "def extract_other_features(annotations_part: str) -> dict:\n",
    "    non_sentiment_feature_tags = {\n",
    "        \"[u]\": False, \n",
    "        \"[p]\": False, \n",
    "        \"[s]\": False, \n",
    "        \"[cc]\": False, \n",
    "        \"[cs]\": False\n",
    "    }\n",
    "    for key, _ in non_sentiment_feature_tags.items():\n",
    "        if key in annotations_part:\n",
    "            non_sentiment_feature_tags[key] = True\n",
    "    return non_sentiment_feature_tags\n",
    "\n",
    "def parse_reviews(file_content) -> pd.DataFrame:\n",
    "    reviews = re.split(r'\\[t\\]', file_content) # Split the content by the review title tag [t]\n",
    "    reviews = reviews[1:] # Skip header by skipping to the first [t] tag\n",
    "\n",
    "    data = []\n",
    "    for review in reviews:\n",
    "        # 1. Remove leading and trailing whitespace from review\n",
    "        # 2. Split into a list of individual lines by '\\n'\n",
    "        # 3. Remove leading and trailing whitespace from individual line\n",
    "        lines = [line.strip() for line in review.strip().split(sep = '\\n')]\n",
    "        \n",
    "        title = lines[0] # First line of each review is the review title\n",
    "        sentences = lines[1:] # The rest are sentences\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Split annotations and sentence text\n",
    "            # The annotations are before '##', the sentence text is after\n",
    "            if '##' in sentence:\n",
    "                annotations_part, sentence_text = sentence.split(sep = '##')\n",
    "            elif '#' in sentence:\n",
    "                annotations_part, sentence_text = sentence.split(sep = '#')\n",
    "            else:\n",
    "                raise Exception(\"Sentence does not contain a pound sign: \" + sentence)\n",
    "            sentiment_dict, sentiment_total = extract_sentiment(annotations_part)\n",
    "            other_features = extract_other_features(annotations_part)\n",
    "            # Append the data\n",
    "            data.append({\n",
    "                'title': title,\n",
    "                'sentence': sentence_text.strip(),\n",
    "                'sentiment_dict': sentiment_dict,\n",
    "                'sentiment_total': sentiment_total,\n",
    "                \"[u]\": other_features['[u]'], \n",
    "                \"[p]\": other_features['[p]'], \n",
    "                \"[s]\": other_features['[s]'],\n",
    "                \"[cc]\": other_features['[cc]'],\n",
    "                \"[cs]\": other_features['[cs]'],\n",
    "                'annotations_part': annotations_part\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Starting with the apex:\n",
    "with open(raw_container_path + file_name_dict['apex_ad2600_dvd_player'], 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "df = parse_reviews(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving parsed text as a (still unclean) csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/apex_ad2600_dvd_player.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "2 out of three ai n't good .                                           5\n",
       "a frustrating christmas .                                              7\n",
       "a great discovery !                                                    4\n",
       "a piece of junk .                                                      6\n",
       "a very embarassing gift .                                              9\n",
       "                                                                      ..\n",
       "when it works , it 's great , when it does n't it 's frustrating .     8\n",
       "worst customer service on record .                                    11\n",
       "worst piece of electronics i ever bought .                            11\n",
       "you get what you paid for .                                            4\n",
       "you get what you pay for .                                            17\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('title').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target sentence on line 485\n"
     ]
    }
   ],
   "source": [
    "target_sentence = \"run[+3], dvd media[+2]#apex ad-2600 runs all the dvd media including dvd + r/rw and dvd-r / rw ( unlike sony or panasonic - one supports only + r/rw and another supports - r/rw ) . \"\n",
    "\n",
    "with open(raw_container_path + file_name_dict['apex_ad2600_dvd_player'], 'r') as f:\n",
    "    for line_num, line in enumerate(f, start=1):\n",
    "        # Check if the target sentence is in the current line\n",
    "        if target_sentence in line:\n",
    "            print(f\"Found target sentence on line {line_num}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Target sentence not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
